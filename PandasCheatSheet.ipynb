{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PandasCheatSheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawalk/datasets/blob/master/PandasCheatSheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS2-Qg-3U3HR",
        "colab_type": "text"
      },
      "source": [
        "##Pandas Cheetsheat - Python \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC29BslqVTB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KEY IMPORTS \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsiIWtWVphU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPORTING DATA\n",
        "\n",
        "pd.read_csv(filename) #from a CSV file\n",
        "pd.read_table(filename) #from a delimited text file(like TSV)\n",
        "pd.read_excel(filename) #from an excel file\n",
        "pd.read_sql(query, connection_object) #from a SQL table/database\n",
        "pd.read_json(json_string) #from a JSON formatted string, URL file.\n",
        "pd.read_html(url) #parses an html url, string or file and extracts tables to a list\n",
        "pd.read_clipboard() #takes the contents of your clipboard and passes it to read_table()\n",
        "pd.DataFrame(dict) #from a dict, keys for columns names, values for data as lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c93_P3q-Wgcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXPORTING DATA\n",
        "\n",
        "df.to_csv(filename) #write to a CSV file\n",
        "df.to_excel(filename) #write to an excel file\n",
        "df.to_sql(table_name, connection_object) #write to a SQL table\n",
        "df.to_json(filename) #write to a file in JSON format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dG_UcczW5QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Test Objects (useful for testing code segments)\n",
        "\n",
        "pd.DataFrame (np.random.rand(20,5)) #5 columns and 20 rows of random floats\n",
        "pd.Series(my_list) #create a series from an iterable my_list\n",
        "df.index = pd.date_range('1900/1/30', periods=df.shape[0]) #add a date index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3encPKqdg__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING DATAFRAMES\n",
        "\n",
        "#specify values for each column\n",
        "df = pd.DataFrame (\n",
        "          {'a' : [4, 5, 6],\n",
        "           'b' : [7, 8, 9],\n",
        "           'c' : [10, 11, 12]},\n",
        "        index = [1, 2, 3])\n",
        "\n",
        "#specify values for each row\n",
        "df = pd.DataFrame (\n",
        "          {'a' : [4, 5, 6],\n",
        "           'b' : [7, 8, 9],\n",
        "           'c' : [10, 11, 12]},\n",
        "        index = [1, 2, 3],\n",
        "        columns = ['a','b','c'])\n",
        "\n",
        "#create datafram with a MultiIndex\n",
        "df = pd.DataFrame(\n",
        "          {'a' : [4 ,5, 6],\n",
        "           'b' : [7, 8, 9],\n",
        "           'c' : [10, 11, 12]},\n",
        "index = pd.MultiIndex.from_tuples(\n",
        "          [('d',1),('d',2),('e',2)],\n",
        "             names=['n','v']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00uapd4AXW5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VIEWING / INSPECTING/ SUMMARIZING DATA\n",
        "\n",
        "df.head(n) #first n rows of the dataframe\n",
        "df.tail(n) #last n rows of the dataframe\n",
        "df.shape #number of rows and columns in the dataframe\n",
        "df.info() #index, datatype, and memory information\n",
        "df.describe() #summary statistics for numerical values and counts\n",
        "df.apply(pd.Series.value_counts) #unique values and counts for all columns\n",
        "f.['w'].value_counts() #count number of rows with each unique value of variable\n",
        "len(df) #returns number of rows in a dataframe\n",
        "df['w'].nunique() #returns number of distinct values in a column\n",
        "df.sum() #sum values of each object\n",
        "df.count() #count non-NA/null values of each object\n",
        "df.median() #median value of each object\n",
        "df.quantile([0.25, 0.75]) #quantiles of each object\n",
        "df.apply(function) #apply function to each object\n",
        "df.min() #minimum value in each object\n",
        "df.max() #maximum values in each object\n",
        "df.mean() #mean value of each object\n",
        "df.var() #variance of each object\n",
        "df.std() #standard deviation of each object"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaL3kuwIXzbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SELECTION\n",
        "\n",
        "df[col]  #returns column with label col as Series\n",
        "df[[col1, col2]] #returns columns as a new dataframe\n",
        "s.iloc[0] #selection by position\n",
        "s.loc['index_one'] #selection by index\n",
        "df.iloc[0,:] #first row\n",
        "df.iloc[0,0] #first element of first column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWbILQsYO_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DATA CLEANING\n",
        "\n",
        "df.columns = ['a','b' 'c'] #rename columns\n",
        "pd.isnull() #checks for null values, returns boolean array\n",
        "pd.notnull() #opposite of pd.isnull()\n",
        "df.dropna() #drop all rows that contain null values\n",
        "df.dropna(axis=1) #drop all columns that contain null values\n",
        "df.dropna(axis=1, thresh=n) #drop all rows that have less than n non values\n",
        "df.fillna(x) #replace all null values with x\n",
        "s.fillna(s.mean()) #replace all null values with the mean (mean can be replaced with almost any fucntion from the https://docs.python.org/3/library/statistics.html)\n",
        "a.astype(float) #convert the datatype of the series to float\n",
        "s.replace(1, 'one') #replace all values equal to 1 with 'one'\n",
        "s.replace([1, 3], ['one', 'three']) #replace all the 1 with 'one'  and the 3 with 'three'\n",
        "df.rename(columns=lambda x: x + 1) #mass renaming of columns \n",
        "df.reanme(columns = {'old_name' : 'new_name'}) #selective renaming\n",
        "df.set_index('column_one') #change the index\n",
        "df.rename(index=lambda x: x + 1) #mass renaming of index\n",
        "df.sort_index() #sort the index of a dataframe\n",
        "df.reset_index() #reset index of dataframe to row numberes, moving index to columns\n",
        "df.drop(columns=['Length', 'Height']) #drop columns from dataframe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DLeZAvUZ0hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FILTER, SORT, AND GROUPBY (RESHAPING DATA)\n",
        "\n",
        "df[df[col] > 0.5] #rows where the column col is great than 0.5\n",
        "df[(df[col] > 0.5) & (df[col] < 0.7)] #rows where 0.7 > col > 0.5\n",
        "df.sort_values(col1) #sort values by col1 in ascending order\n",
        "df.sort_values(col2, ascending=False) #sort values by col2 in descending order\n",
        "df.sort_values([col1, col2], asecnding = [True, False]) #sort values by col1 in ascending order then col2 by descending order\n",
        "df.grouby(col) #returns a groupby object for values from one column\n",
        "df.groupby([col1,col2]) #returns groupby object for values from multiple columns\n",
        "df.groupby(col1)[col2] #returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any fucntion from the https://docs.python.org/3/library/statistics.html)\n",
        "df.pivot_table(index=col1, values=[col2, col3], aggfunc=mean) #create a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
        "df.pivot(columns='var', values='val') #spread rows into columns\n",
        "df.groupby(col1).agg(np,mean) #find the average across all columns for eveny unique col1 group\n",
        "df.apply(np.mean) #apply the function np.mean() across each column\n",
        "nf.apply(np.max,axis=1) #apply the function np.max() across each row\n",
        "df.size() #size of each group\n",
        "df.agg(func) #aggregate group using function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD1TyU3zbmV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#JOIN/COMBINE\n",
        "\n",
        "df1.append(df2) #add the rows in df1 to the end of df2 (columns should be identical)\n",
        "pd.concat([df1, df2], axis=1) #add the columns in df1 to the end of df2 (rows should be identical)\n",
        "pd.concat([df1,df2]) #append rows of dataframes\n",
        "pd.melt(df) #gather columns into rows\n",
        "df1.join(df2, on=col1, how='inner') #SQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. 'how can be on of 'left', 'right', 'outer', 'inner'\n",
        "pd.merge(adf, bdf, how'left', on='x1') #join matching rows from bdf to adf\n",
        "pd.merge(adf, bdf, how='right', on='x1') #join matching rows from adf to bdf\n",
        "pd.merge(adf, bdf, how='inner', on='x1') #join data. Retain only rows in both sets\n",
        "pd.merge(adf, bdf, how='outer', on='x1') # join data retain all values in all rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlJGPPpnkNBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MAKE NEW COLUMNS \n",
        "\n",
        "df.assign(Area=lambda df: df.Length*df.Height) #compute and append one or more new columns\n",
        "df['Volume'] = df.Length*df.Height*df.Depth #add a single column\n",
        "pd.qcut(df.col, n, lables=False) #bin column into n buckets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMFeGIwSgMu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SUBSET OBSERVATIONS (ROWS)\n",
        "\n",
        "df[df.Length > 7] #extract rows that meet logical criteria\n",
        "df.drop_duplicates() #remove duplicate rows (only considers columns)\n",
        "df.sample(frac=0.5) #randomly select fraction of rows\n",
        "df.sample(n=10) #randomly select n rows\n",
        "df.nlargest(n, 'value') #select and order top n entries\n",
        "df.nsmallest(n, 'values') #select and order bottom n entries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsutlOejg4H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SUBSET VARIABLES (COLUMNS)\n",
        "\n",
        "df[['width', 'length', 'species']] #select multiple columns with specific names\n",
        "df['width'] or df.width #select single column with specific name\n",
        "df.filter(regex='regex') #select columnds whose name matches regular expresion regex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD1jwHvEhR8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#REGEX (REGULAR EXPRESSIONS) EXAMPLES\n",
        "\n",
        "'\\.' #mathes strings containing a period '.'\n",
        "'Length$' #matches strings ending in the worh 'Length'\n",
        "'^Sepal' #matches strings begining with the word \"Sepal\"\n",
        "'^x[1-5]$' #matches strings begining with 'x and ending with 1, 2, 3, 4, 5\n",
        "'^(?!Species$).*' #matches strings exept the string \"Species\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5eqthiTcNp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STATISTICS (can be applied to a series as well)\n",
        "\n",
        "df.describe() #summary statistics for nummerical columns\n",
        "df.mean() #returns the mean of all columns\n",
        "df.corr() #returns the coorelation between columns in a dataframe\n",
        "df.count() #returns the number of non-null values in each dataframe column \n",
        "df.max() #returns the hightest value in each column\n",
        "df.min() #returns the lowest values in each column\n",
        "df.median() #returns the median of each column\n",
        "df.std() #returns the standard deviation of each column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUSC2fnBlosu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PLOTTING \n",
        "\n",
        "df.plot.hist() #histogram for each column\n",
        "df.plot.scatter(x='w', y='h') #scatter plot using pairs of points (x,y)\n",
        "sns.lineplot() #a line plot with possibility of several semantic groupings\n",
        "sns.pairplot() #plot pairwise relationships in a dataset\n",
        "sns.boxplot() #draws a box plot to show distributions with respect to categories \n",
        "sns.heatmap() #plot rectangular data as a color-encoded matrix\n",
        "sns.lmplot() #plot data and regression model fits across a FacetGrid\n",
        "sns.violinplot() #draw a combination of boxplot and kernel density estimate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJGXGDhYdKTt",
        "colab_type": "text"
      },
      "source": [
        "Taken from \n",
        "\n",
        "\\\\\n",
        "https://www.dataquest.io/blog/pandas-cheat-sheet/\n",
        "\n",
        "\\\\\n",
        "https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
        "\n",
        "\\\\\n",
        "And various random internet/lecture sources\n",
        "\n",
        "\n"
      ]
    }
  ]
}